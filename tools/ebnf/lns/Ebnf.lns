// -*- coding: utf-8 -*-

_lune_control default_async_all;

import lns.Util;
import lns.Code;
import lns.EbnfDef;
import go/github:com.ifritJP.LuneScript.src.lune.base.Tokenizer as LnsTokenizer;
import go/github:com.ifritJP.LuneScript.src.lune.base.Types as LnsTypes;

pub let defaultEbnfPath = "../../../ifritJP.github.io/hugo/content/LuneScript/ebnf.ja.org";

pub class EbnfTokenizer {
   let tokenizer:LnsTokenizer.PushbackTokenizer;
   let mut inEbnf:bool {pub,pub};

   fn __init( tokenizer:LnsTokenizer.Tokenizer, inEbnf:bool ) {
      self.tokenizer = new LnsTokenizer.DefaultPushbackTokenizer( tokenizer );
      self.inEbnf = inEbnf;
   }

   pub static fn create( path:str! ) : EbnfTokenizer {
      let src;
      let inEbnf;
      when! path {
         src = LnsTypes.TokenizerSrc.LnsPath( nil, path, "ebnf", nil );
         inEbnf = false;
      } else {
         src = EbnfDef.getEbnfSrc();
         inEbnf = true;
      }
      let mut tokenizer = LnsTokenizer.StreamTokenizer.create(
         src, false, nil, nil );
      return new EbnfTokenizer( tokenizer, inEbnf );
   }

   pri fn checkRawNext( txt:str ) mut : &LnsTypes.Token {
      let token = self.tokenizer.getTokenNoErr( false );
      if token.txt == txt {
         return token;
      }
      Util.log(
         "%d:%d: Illegal token. expects '%s' but '%s'"
         ( token.pos.lineNo, token.pos.column, txt, token.txt) );
      os.exit( 1 );
   }
   
   pub fn getToken() mut : &LnsTypes.Token {
      let token = self.tokenizer.getTokenNoErr(false);
      switch token.txt {
         case "#" {
            let nextToken = self.tokenizer.getTokenNoErr(false);
            if nextToken.txt == "+" and nextToken.consecutive {
               return new LnsTypes.Token( .Dlmt, "#+", token.pos, false, nil );
            }
            self.tokenizer.pushback();
         }
         case ":" {
            let nextToken = self.tokenizer.getTokenNoErr( false );
            if nextToken.txt == ":" {
               self.checkRawNext( "=" );
               return new LnsTypes.Token( .Dlmt, "::=", token.pos, false, nil );
            } else {
               self.tokenizer.pushback();
            }
         }
         case "<" {
            if self.inEbnf {
               let nextToken = self.tokenizer.getTokenNoErr( false );
               self.checkRawNext( ">" );
               return new LnsTypes.Token(
                  .Type, "<%s>" (nextToken.txt), token.pos, false, nil );
            }
         }
      }
      return token;
   }

   pub fn checkNext( txt:str ) mut : &LnsTypes.Token {
      let token = self.getToken();
      if token.txt == txt {
         return token;
      }
      Util.log(
         "%d:%d: Illegal token. expects '%s' but '%s'"
         ( token.pos.lineNo, token.pos.column, txt, token.txt) );
      os.exit( 1 );
   }

   pub fn pushBack( token:&LnsTypes.Token ) mut {
      self.tokenizer.pushbackToken( token );
   }

   pub fn skipLine( curToken:&LnsTypes.Token ) mut {
      let mut token = self.getToken();
      while token.pos.lineNo == curToken.pos.lineNo {
         token = self.getToken();
      }
      self.pushBack( token );
   }
}



pub alge ParseCodeRet {
   /** EOF */
   Eof,
   /** 不適合 */
   Unmatch,
   /** 省略 */
   Abbr,
   /** 検出 */
   Detect(&Code.CodeCore),
}


pub class Candidate {
   let txtSet:Set<str>;
   let excludeTxtSet:Set<str>;
   let mut hasExcludeTxt:bool;
   let tokenKindSet:Set<LnsTypes.TokenKind>;
   let mut canAbbr:bool {pub};
   let mut any:bool {pub};

   pub fn __init(canAbbr:bool, any:bool ) {
      self.canAbbr = canAbbr;
      self.txtSet = (@);
      self.excludeTxtSet = (@);
      self.hasExcludeTxt = false;
      self.tokenKindSet = (@);
      self.any = any;
   }

   pub fn addTxt( txt:str ) mut {
      self.txtSet.add( txt) ;
   }
   pub fn addExcludeTxt( txt:str ) mut {
      self.excludeTxtSet.add( txt) ;
      self.hasExcludeTxt = true;
   }
   pub fn addTokenKind( kind:LnsTypes.TokenKind ) mut {
      self.tokenKindSet.add( kind ) ;
   }
   pub fn add( other:&Candidate, validAbbr:bool ) mut {
      self.txtSet.or( other.txtSet );
      self.tokenKindSet.or( other.tokenKindSet );
      self.excludeTxtSet.or( other.excludeTxtSet );
      self.hasExcludeTxt = other.hasExcludeTxt;
      if validAbbr {
         self.canAbbr = self.canAbbr and other.canAbbr;
      }
      self.any = self.any and other.any;
   }

   pub fn hasTxt( txt:str ) : bool {
      if self.hasExcludeTxt {
         return not self.excludeTxtSet.has( txt );
      }
      return self.txtSet.has( txt );
   }
   pub fn hasKind( kind:LnsTypes.TokenKind ) : bool {
      return self.tokenKindSet.has( kind );
   }
   pub fn has( token:&LnsTypes.Token ) : bool {
      return self.hasTxt( token.txt ) or self.hasKind( token.kind );
   }

   pub fn dump( stream:oStream ) {
      stream.write( "txt: " );
      foreach txt in self.txtSet {
         stream.write( "%s, " (txt) );
      }
      stream.write( "\n" );
      stream.write( "kind: " );
      foreach kind in self.tokenKindSet {
         stream.write( "%s, " (kind.$_txt));
      }
      stream.write( "\n" );
      stream.write( "abbr: %s, any: %s\n" (self.canAbbr, self.any ) );
   }
}


pub proto interface Core;
pub proto interface EbnfCtrlIF;
pub interface RuleListIF {
   pub fn setupCandidate( ctrl:&EbnfCtrlIF, usedCoreSet:Set<&Core>) mut : &Candidate;
   pub fn parseCode( ctrl:&EbnfCtrlIF, tokenizer:Code.CodeTokenizer,
                     usedElementSet:Set<&str> ) : ParseCodeRet;
}
pub interface RuleIF {
   pub fn setupCandidate( ctrl:&EbnfCtrlIF, usedCoreSet:Set<&Core>) mut : &Candidate;
   pub fn parseCode( ctrl:&EbnfCtrlIF, tokenizer:Code.CodeTokenizer,
                     usedElementSet:Set<&str> ) : ParseCodeRet;
}
pub interface EbnfCtrlIF {
   pub fn getRuleList( name:str ) : RuleListIF!;
}

/**
ebnf の element を構成する一つの要素

以下の "if", <exp>, <block> の部分。

<hoge> ::= "if" <exp> <block>
*/
pub interface Core {
   pub fn setupCandidate( ctrl:&EbnfCtrlIF, usedCoreSet:Set<&Core>) mut : &Candidate;
   pub fn get_candidate(): &Candidate;
   pub fn parseCode(
      ctrl:&EbnfCtrlIF, tokenizer:Code.CodeTokenizer,
      usedElementSet:Set<&str>):ParseCodeRet;
}


/**
Token を Core として管理するクラス

以下の "if" の部分。

<hoge> ::= "if" <exp> <block>
 */
pub class TokenCore extend (Core) {
   let token:&LnsTypes.Token {pub};
   let rawTxt:str;
   let candidate:Candidate {pub&};
   
   pub fn __init( token:&LnsTypes.Token ) {
      self.token = token;
      self.rawTxt = token.getExcludedDelimitTxt();
      self.candidate = new Candidate( false, false );
      self.candidate.addTxt( self.rawTxt );
   }
   pub fn setupCandidate( ctrl:&EbnfCtrlIF, usedCoreSet:Set<&Core>) mut : &Candidate {
      return self.candidate;
   }
   pub fn parseCode(
      ctrl:&EbnfCtrlIF, tokenizer:Code.CodeTokenizer,
      usedElementSet:Set<&str>):ParseCodeRet
   {
      let token = tokenizer.getToken();
      Util.log( __func__, self.token.txt, token.txt, token.kind.$_txt );
      if token.txt == self.rawTxt {
         Util.log( __func__, "detect", token.txt,
                "%d:%d" (token.pos.lineNo, token.pos.column ) );
         return .Detect( new Code.CodeCoreToken( token ) );
      }
      tokenizer.pushback();
      if token.kind == .Eof {
         return .Eof;
      }
      return .Unmatch;
   }
}

class BuiltinTokenKindCore extend (Core) {
   let elementName:str;
   let tokenKindSet:__Set<LnsTypes.TokenKind>;
   let candidate:Candidate {pub&};
   
   pub fn __init( elementName:str, tokenKindSet:__Set<LnsTypes.TokenKind> ) {
      self.elementName = elementName;
      self.tokenKindSet = tokenKindSet;
      self.candidate = new Candidate( false, false );
      foreach kind in tokenKindSet {
         self.candidate.addTokenKind( kind );
      }
   }

   pub fn setupCandidate( ctrl:&EbnfCtrlIF, usedCoreSet:Set<&Core>) mut : &Candidate {
      return self.candidate;
   }
   pub fn parseCode(
      ctrl:&EbnfCtrlIF, tokenizer:Code.CodeTokenizer,
      usedElementSet:Set<&str>):ParseCodeRet
   {
      let token = tokenizer.getToken();
      if self.tokenKindSet.has( token.kind ) {
         Util.log( __func__, "detect", self.elementName );
         return .Detect( new Code.CodeCoreBuiltin( token ) );
      }
      tokenizer.pushback();
      return .Unmatch;
   }
}

class BuiltinTokenCore extend (Core) {
   let elementName:str;
   //let excludeTxtSet:__Set<str>;
   let candidate:Candidate {pub&};

   pub fn __init( elementName:str, excludeTxtSet:__Set<str> ) {
      self.elementName = elementName;
      //self.excludeTxtSet = excludeTxtSet;
      self.candidate = new Candidate( false, false );
      foreach txt in excludeTxtSet {
         self.candidate.addExcludeTxt( txt );
      }
   }

   pub fn setupCandidate( ctrl:&EbnfCtrlIF, usedCoreSet:Set<&Core>) mut : &Candidate {
      return self.candidate;
   }
   pub fn parseCode(
      ctrl:&EbnfCtrlIF, tokenizer:Code.CodeTokenizer,
      usedElementSet:Set<&str>):ParseCodeRet
   {
      let token = tokenizer.getToken();
      //if not self.excludeTxtSet.has( token.txt ) {
      if self.candidate.hasTxt( token.txt ) {
         Util.log( __func__, "detect", self.elementName );
         return .Detect( new Code.CodeCoreBuiltin( token ) );
      }
      tokenizer.pushback();
      return .Unmatch;
   }
}

class BuiltinStatCore extend (Core) {
   let candidate:Candidate {pub&};

   pub fn __init() {
      self.candidate = new Candidate( false, true );
   }
   
   pub fn setupCandidate( ctrl:&EbnfCtrlIF, usedCoreSet:Set<&Core>) mut : &Candidate {
      return self.candidate;
   }
   pub fn parseCode(
      ctrl:&EbnfCtrlIF, tokenizer:Code.CodeTokenizer,
      usedElementSet:Set<&str>):ParseCodeRet
   {
      let list:List<&LnsTypes.Token> = [];
      let mut depth = 1;
      while true {
         let mut workToken = tokenizer.getToken();
         if workToken.kind == .Eof {
            return .Eof;
         }
         switch workToken.txt {
            case "}" {
               depth = depth - 1;
               if depth == 0 {
                  break;
               }
            }
            case "{", "`{" {
               depth = depth + 1;
            }
         }
         list.insert( workToken );
      }
      tokenizer.pushback();
      return .Detect( new Code.CodeCoreStat( list ));
   }
}


class BuiltinCore {
   local static let elementNameMap:Map<str,Core>;
   __init {
      BuiltinCore.elementNameMap = {};

      {
         let map:__Map<str,__Set<LnsTypes.TokenKind>> = {
            "<shebang>": (@ .Sheb),
            "<eof>": (@ .Eof ),
            "<sym>": (@ .Symb, .Type, .Kywd, .Ope ),
            "<literal_str>": (@ .Str ),
            "<literal_int>": (@ .Int ),
            "<literal_real>": (@ .Real ),
            "<literal_char>": (@ .Char ),
         };
         foreach tokenKindSet, elementName in map {
            BuiltinCore.elementNameMap[ elementName ] = new BuiltinTokenKindCore(
               elementName, tokenKindSet );
         }
      }

      {
         let map:__Map<str,__Set<str>> = {
            "<token>": (@ ";"),
         };
         foreach excludeTxtSet, elementName in map {
            BuiltinCore.elementNameMap[ "<token>" ] = new BuiltinTokenCore(
               elementName, excludeTxtSet );
         }
      }
      BuiltinCore.elementNameMap[ "<stat>" ] = new BuiltinStatCore();
   }
   pub static fn get( elementName:str ) __noasync : Core! {
      return BuiltinCore.elementNameMap[ elementName ];
   }
}

/**
element を Core にするクラス。

以下の <exp>, <block> の部分。

<hoge> ::= "if" <exp> <block>
*/
pub class ElementCore extend (Core) {
   let elementName:str;
   let candidate:Candidate {pub&};
   pri fn __init( elementName:str ) {
      self.elementName = elementName;
      self.candidate = new Candidate( true, false );
   }
   pub static fn create(
      elementName2Core:Map<str,Core>, elementName:str ) : Core
   {
      let! mut core = elementName2Core[ elementName ] {
         __asyncLock {
            if! BuiltinCore.get( elementName ) {
               core = _exp;
            } else {
               core = new ElementCore( elementName );
            }
         }
         elementName2Core[ elementName ] = core;
      };
      return core;
   }
   pub fn setupCandidate( ctrl:&EbnfCtrlIF, usedCoreSet:Set<&Core>) mut : &Candidate {
      Util.log( __func__, self.elementName );
      if not usedCoreSet.has( self ) {
         usedCoreSet.add( self );
         if! let mut ruleList = ctrl.getRuleList( self.elementName ) {
            self.candidate.add(ruleList.setupCandidate( ctrl, usedCoreSet ), true );
         } else {
            error( "unknown -- %s" (self.elementName) );
         }
      } else {
         Util.log( "already:", self.elementName );
      }
      return self.candidate;
   }
   pub fn parseCode(
      ctrl:&EbnfCtrlIF, tokenizer:Code.CodeTokenizer,
      usedElementSet:Set<&str>):ParseCodeRet
   {
      let! ruleList = ctrl.getRuleList( self.elementName ) {
         return .Unmatch;
      };
      return ruleList.parseCode( ctrl, tokenizer, usedElementSet );
   }
}

pub fn isElement( token:&LnsTypes.Token ) : bool {
   return token.kind == .Type and token.txt[1] == ?<;
}


pub class DeclTokenizer {
   let tokenizer:EbnfTokenizer;
   let mut prevToken:LnsTokenizer.Token;
   let allElementSet:Set<str>;

   pub fn __init( tokenizer:EbnfTokenizer, prevToken:LnsTokenizer.Token,
                  allElementSet:Set<str> )
   {
      self.tokenizer = tokenizer;
      self.prevToken = prevToken;
      self.allElementSet = allElementSet;
   }
   
   pub fn getToken() mut : &LnsTypes.Token! {
      let nextToken = self.tokenizer.getToken();
      if nextToken.kind == .Eof {
         return nil;
      }
      if nextToken.pos.lineNo ~= self.prevToken.pos.lineNo {
         if nextToken.txt == "#+" {
            self.tokenizer.pushBack( nextToken );
            return nil;
         }
         let checkToken = self.tokenizer.getToken();
         self.tokenizer.pushBack( checkToken );
         if checkToken.txt == "::=" {
            self.tokenizer.pushBack( nextToken );
            return nil;
         }
      }
      if isElement( nextToken ) {
         self.allElementSet.add( nextToken.txt );
      }
      self.prevToken = nextToken;
      return nextToken;
   }

   pub fn err( mess:str ) {
      Util.log( "%d:%d:" (self.prevToken.pos.lineNo, self.prevToken.pos.column), mess );
      os.exit( 1 );
   }
}
