// -*- coding: utf-8 -*-

_lune_control default_async_all;

import lns.Util;
import lns.Ebnf;
import lns.Rule;
import lns.Code;
import go/github:com.ifritJP.LuneScript.src.lune.base.Tokenizer as LnsTokenizer;
import go/github:com.ifritJP.LuneScript.src.lune.base.Types as LnsTypes;

pub class EbnfCtrl extend (Ebnf.EbnfCtrlIF) {
   // element 名 → RuleList マップ
   let element2ruleList:Map<str,Rule.RuleList>;
   let allElementSet:Set<str>;
   let elementName2Core:Map<str,Ebnf.Core>;

   pub fn __init() {
      self.element2ruleList = {};
      self.allElementSet = (@);
      self.elementName2Core = {};
   }

   pub fn getRuleList( name:str ) : Ebnf.RuleListIF! {
      return self.element2ruleList[ name ];
   }
}


fn EbnfCtrl.processRule(
   elementName:str!, tokenizer:Ebnf.DeclTokenizer, termTxt:str! ) mut : Rule.Rule!, str
{
   let mut coreList:List<Ebnf.Core> = [];
   let mut endsTerm = false;
   while true {
      let! token = tokenizer.getToken() {
         break;
      };
      switch token.txt {
         case "[" {
            let mut optRule = self.processRule( nil, tokenizer, "]" )!;
            coreList.insert( new Rule.RuleCore( .Option, optRule ) );
         }
         case "{" {
            let mut optRule = self.processRule( nil, tokenizer, "}" )!;
            coreList.insert( new Rule.RuleCore( .Repeat, optRule ) );
         }
         case "|" {
            break;
         }
         case termTxt {
            endsTerm = true;
            break;
         }
         default {
            if Ebnf.isElement( token ) {
               coreList.insert(
                  Ebnf.ElementCore.create( self.elementName2Core,token.txt ) );
            } else {
               coreList.insert( new Ebnf.TokenCore( token ) );
            }
         }
      }
   }
   if #coreList == 0 {
      return nil, "coreList is 0";
   }
   if termTxt and not endsTerm {
      return nil, "not end term -- %s" (termTxt) ;
   }
   return new Rule.Rule( elementName, coreList ), "";
}


local fn EbnfCtrl.processDecl(
   tokenizer:Ebnf.EbnfTokenizer, symbolToken:&LnsTypes.Token ) mut : &Rule.RuleList
{
   let elementName = symbolToken.txt;
   Util.log( __func__, elementName );
   tokenizer.checkNext( "::=" );

   self.allElementSet.add( elementName );

   let mut list:List<Rule.Rule> = [];
   while true {
      let mut declTokenizer = new Ebnf.DeclTokenizer(
         tokenizer, symbolToken, self.allElementSet );
      let mut rule, mess = self.processRule( elementName, declTokenizer, nil );
      when! rule {
         list.insert( rule );
      } else {
         if #list == 0 {
            declTokenizer.err( mess );
         }
         break;
      }
   }
   let mut ruleList = new Rule.RuleList( elementName, list );
   self.element2ruleList[ elementName ] = ruleList;
   return ruleList;
}

pub fn EbnfCtrl.dump() {
   Util.log( "=================" );
   forsort element in self.allElementSet {
      let ruleList = self.element2ruleList[ element ];
      Util.log( ruleList ~= nil, element );
      if! let core = self.elementName2Core[ element ] {
         core.$candidate.dump( io.stdout );
      }
   }
}

pub fn EbnfCtrl.parse( elementName:str, tokenizer:Code.CodeTokenizerIF,
                       hook:Code.ParseCodeHookIF ) : Code.ParseCodeRet
{
   let! ruleList = self.element2ruleList[ elementName ] {
      Util.log( "error parse" );
      return .Unmatch;
   };
   let depth = 0;
   hook.prepare( elementName, depth, tokenizer.getToken() );
   tokenizer.pushback();
   return hook.process( ruleList.parseCode( self, tokenizer, hook, depth ), depth );
}

pub fn EbnfCtrl.setupCandidate() mut {
   let fusedCoreSet:Set<&Ebnf.Core> = (@);
   foreach ruleList in self.element2ruleList {
      ruleList.setupCandidate( self, fusedCoreSet );
   }
}

pub fn analyze_ebnf( tokenizer:Ebnf.EbnfTokenizer ) : &EbnfCtrl {
   let mut ebnfCtrl = new EbnfCtrl();
   
   while true {
      let token = tokenizer.getToken();
      if token.kind == .Eof {
         break;
      }
      if token.txt == "#" {
         tokenizer.skipLine( token );
      } elseif token.txt == "#+" {
         let nextToken = tokenizer.getToken();
         switch nextToken.txt.upper() {
            case "BEGIN_SRC" {
               tokenizer.set_inEbnf( true );
            }
            case "END_SRC" {
               tokenizer.set_inEbnf( false );
            }
         }
         tokenizer.skipLine( token );
      } elseif tokenizer.$inEbnf {
         if Ebnf.isElement( token ) {
            ebnfCtrl.processDecl( tokenizer, token );
         }
      }
   }

   ebnfCtrl.setupCandidate();
   
   return ebnfCtrl;
}
