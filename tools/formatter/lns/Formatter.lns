// -*- coding:utf-8; -*-

_lune_control default_strict_generics;
_lune_control default_async_all;

import lns.Code;
import lns.Util;
import go/github:com.ifritJP.LuneScript.src.lune.base.Types as LnsTypes;
import go/github:com.ifritJP.LuneScript.src.lune.base.Writer as LnsWriter;
import go/github:com.ifritJP.LuneScript.src.lune.base.Util as LnsUtil;
import go/github:com.ifritJP.LuneScript.src.lune.base.AsyncTokenizer as LnsAsyncTokenizer;


let termTxtSet = (@ "]", ")", "}" );
let beginTxtSet = (@ "[", "(", "{", "[@", "(@", "[=", "`{" );

let parenMap = {
   "[":"]",
   "(":")",
   "{":"}",
   "[@":"]",
   "(@":")",
   "[=":"]",
   "`{":"}",
   "case":"",
   // EOF 用
   "":"",
};

let indentTermTxtSet = ( (@ ",", ";" ) );


fn getTokenTxt( token:&LnsTypes.Token ) : str {
   let pos = token.pos;
   return "%d:%d:%s" (pos.lineNo, pos.column, token.txt);
}


interface PickCore {
   pub fn collect( pickedTokenList:List<&LnsTypes.Token> );
}

class PickCoreToken extend (PickCore) {
   let token:&LnsTypes.Token {pub};

   pub fn collect( pickedTokenList:List<&LnsTypes.Token> ) {
      if self.token.kind ~= .Eof {
         pickedTokenList.insert( self.token );
      }
   }
}

class PickPareInfo extend (PickCore) {
   let startToken:&LnsTypes.Token {pub};
   /** 終了トークン */
   let termTxt:str {pub};
   /** このペア情報に含まれる token の list */
   let mut coreList:List<PickCore>;
   /** */
   let mut closed:bool {pub,pub};

   pub fn __init( startToken:&LnsTypes.Token ) {
      self.startToken = startToken;
      self.termTxt = unwrap parenMap[ startToken.txt ];
      self.coreList = [];
      self.coreList.insert( new PickCoreToken( startToken ) );
      self.closed = false;
   }

   pub fn add( token:&LnsTypes.Token ) mut {
      self.coreList.insert( new PickCoreToken( token ) );
   }
   pub fn addCore( core:PickCore ) mut {
      self.coreList.insert( core );
   }
   fn clearSub() mut {
      let list:List<PickCore> = [];
      list.insert( self.coreList[ 1 ] );
      if self.closed {
         list.insert( self.coreList[ #self.coreList ] );
      }
      self.coreList = list;
   }
   pub fn clear() mut {
      foreach core in self.coreList {
         if! let mut pick = core@@@PickPareInfo {
            pick.clearSub();
         }
      }
   }

   pub fn collect( pickedTokenList:List<&LnsTypes.Token> ) {
      foreach core in self.coreList {
         core.collect( pickedTokenList );
      }
   }
}

/**
大きいファイルの全体を処理対象にすると時間がかかるので、
必要最低限の領域を pickup する。
*/
pub class CodePicker extend Code.CodeTokenizerBase {
      
   let pickedTokenList:List<&LnsTypes.Token>;
   let mut curIndex:int;
   
   pub fn __init() {
      super();
      self.pickedTokenList = [];
      self.curIndex = 0;
   }
   
   pro override fn getTokenMain() mut : &LnsTypes.Token! {
      if #self.pickedTokenList < self.curIndex + 1 {
         return nil;
      }
      self.curIndex = self.curIndex + 1;
      return self.pickedTokenList[ self.curIndex ];
   }

   fn dump() mut {
      foreach _ in self.pickedTokenList {
         let prev = self.getPrevToken();
         let token = self.getToken();
         if prev.pos.lineNo ~= token.pos.lineNo {
            print( "" );
         }
         io.stdout.write( token.txt .. " " );
      }
   }

   pub static fn createFrom(
      tokenizer:Code.CodeTokenizerIF, startLineNo:int, endLineNo:int ) : CodePicker
   {
      fn process( curInfo:PickPareInfo ) __trans : bool {
         while true {
            let token = tokenizer.getToken();
            if token.kind == .Eof {
               return false;
            }
            if token.txt ~= "case" and parenMap[ token.txt ] {
               let mut nextInfo = new PickPareInfo( token );
               //print( __func__, "push", getTokenTxt( token ) );
               let result = process( nextInfo );
               if result {
                  curInfo.clear();
               }
               curInfo.addCore( nextInfo );
               if result {
                  return true;
               }
            } elseif token.txt == curInfo.$termTxt {
               //print( __func__, "pop", getTokenTxt( token ) );
               curInfo.add( token );
               curInfo.set_closed( true );
               if token.pos.lineNo >= startLineNo {
                  return true;
               }
               return false;
            } else {
               curInfo.add( token );
            }

            if token.pos.lineNo >= startLineNo {
               return true;
            }
         }
      }

      
      let pickPareInfoStack:List<PickPareInfo> = [];
      let mut curInfo = new PickPareInfo( LnsTypes.noneToken );
      pickPareInfoStack.insert( curInfo );


      process( curInfo );

      let mut codePicker = new CodePicker();
      pickPareInfoStack[ 1 ].collect( codePicker.pickedTokenList );

      while true {
         let token = tokenizer.getToken();
         if token.kind == .Eof or token.pos.lineNo > endLineNo {
            break;
         }
         codePicker.pickedTokenList.insert( token );
      }
      

      // if true {
      //    codePicker.dump();
      //    os.exit(1);
      // }
      
      return codePicker;
   }
}




let indentDelta = 3;

pub class LineIndent {
   let token:&LnsTypes.Token {pub};
   /** 行頭インデント */
   let indent:int {pub};
   /** インデントを決定したコード上の場所 */
   let decidePos:int {pub};
   /** 現在の位置からの offset */
   let delta:int {pub};
}

pub class Line2Indent {
   let lineno2indent:Map<int,&LineIndent> {pub&};
   let indentList:List<&LineIndent>;
   let mut latestLineIndent:&LineIndent!;

   pub fn __init() {
      self.latestLineIndent = nil;
      self.lineno2indent = {};
      self.indentList = [];
      self.indentList.insert( new LineIndent( LnsTypes.noneToken, 1, 1, 0 ) );
   }
   
   pub fn add( lineNo:int, lineIndent:&LineIndent ) mut {
      if not self.lineno2indent[ lineNo ] {
         self.lineno2indent[ lineNo ] = lineIndent;
         self.indentList.insert( lineIndent );
      }
   }
   pub fn getPrevIndent() : &LineIndent {
      return self.indentList[ #self.indentList ];
   }
   pub fn get( lineNo:int, column:int ) : int {
      let! lineIndent = self.lineno2indent[ lineNo ] {
         return column;
      };
      return lineIndent.$delta + column;
   }

   pub fn outputResult( stream:oStream ) {
      let mut json = new LnsWriter.JSON( stream );
      json.startParent( "indent", false );

      if! let latest = self.latestLineIndent {
         json.startParent( "latest", false );
         json.write( "debugLineNo", latest.$decidePos );
         json.write( "column", latest.$indent );
         json.endElement();
      }
      
      json.startParent( "lines", true );
      forsort lineIndent, line in self.$lineno2indent {
         json.startParent( "%d" (line), false );
         json.write( "debugLineNo", lineIndent.$decidePos );
         json.write( "column", lineIndent.$indent );
         json.write( "lineNo", line );
         json.write( "same", lineIndent.$token.$pos.column == lineIndent.$indent );
         json.endElement();
      }
      json.endElement();
      json.endElement();
      json.endLayer();
   }
}


proto class ParenInfo;
alge ParenInfoIndent {
   // 絶対位置
   Abs( column:int ),
   // parenInfo の indent からの offset 位置
   RelIndent( parenInfo:&ParenInfo, offset:int ),
   // parenInfo の termIndent からの offset 位置
   RelTerm( parenInfo:&ParenInfo, offset:int ),
   // parenInfo の termIndent から startToken 相対 offset 位置
   RelTermPos( parenInfo:&ParenInfo, offset:int ),
}

class ParenInfo {
   let line2Indent:&Line2Indent;
   let parentInfo:&ParenInfo;
   /** hook の depth */
   let depth:int {pub};
   /** 開始トークン */
   let startToken:&LnsTypes.Token {pub};
   /** 終了トークン */
   let termTxt:str {pub};
   /** startToken に続いて同じ行に続いているトークン */
   let mut contToken:&LnsTypes.Token!;
   /** 行頭のトークンを待っているかどうか */
   let mut isWaitingFront:bool;
   /** 行頭のトークン */
   let mut frontToken:&LnsTypes.Token!;
   /** termTxt のインデント */
   let mut termIndent:&ParenInfoIndent;
   /** インデント */
   let mut indent:&ParenInfoIndent;

   pub fn set_frontToken( token:&LnsTypes.Token! ) mut {
      self.frontToken = token;
      self.isWaitingFront = token == nil;
   }

   fn get_indentPos( parenInfoIndent:&ParenInfoIndent ) : int;

   pub fn get_stmtIndent() : int {
      return self.get_indentPos( self.indent );
   }
   pub fn get_indent() : int {
      let indent = self.get_indentPos( self.indent );
      if self.isWaitingFront {
         return indent;
      }
      return indent + indentDelta;
   }
   pub fn get_termIndent() : int {
      return self.get_indentPos( self.termIndent );
   }
   
   fn get_indentPos( parenInfoIndent:&ParenInfoIndent ) : int {
      _match parenInfoIndent {
         case .Abs( column ) {
            return column;
         }
         case .RelIndent( tokenIndent, offset ) {
            return tokenIndent.$stmtIndent + offset;
         }
         case .RelTerm( tokenIndent, offset ) {
            return tokenIndent.$termIndent + offset;
         }
         case .RelTermPos( tokenIndent, offset ) {
            let correct = self.line2Indent.get( self.parentInfo.startToken.pos.lineNo, 0 );
            //           print( "hoge:", tokenIndent.$termIndent, correct, offset );
            return tokenIndent.$termIndent + correct + offset;
         }
      }
   }

   pub fn set_contToken( contToken:&LnsTypes.Token ) mut {
      if self.isWaitingFront {
         self.set_frontToken( contToken );
      }
      if self.contToken {
         return;
      }
      if self.startToken.pos.lineNo ~= contToken.pos.lineNo {
         return;
      }
      self.contToken = contToken;
      self.termIndent = ParenInfoIndent.RelTerm(
         self.parentInfo, #self.startToken.txt + indentDelta  );
      if self.startToken.txt == "case" {
      } else {
         self.indent = ParenInfoIndent.RelTermPos(
            self.parentInfo,
            contToken.pos.column - self.parentInfo.$termIndent );
         self.termIndent = ParenInfoIndent.RelTermPos(
            self.parentInfo,
            contToken.pos.column - self.parentInfo.$termIndent - indentDelta * 2);
      }
   }

   pub fn __init( line2Indent:&Line2Indent,
                  parentInfo:&ParenInfo!, depth:int, startToken:&LnsTypes.Token )
   {
      self.line2Indent = line2Indent;
      self.parentInfo = parentInfo or self;
      
      self.depth = depth;
      self.startToken = startToken;
      if! parenMap[ startToken.txt ] {
         self.termTxt = _exp;
      } else {
         error( "illegal paren -- %s" (getTokenTxt(startToken)) );
      }
      self.contToken = nil;
      self.isWaitingFront = true;
      self.frontToken = nil;

      let mut termIndent = ParenInfoIndent.Abs( 1 );
      let mut offset = 0;
      if parentInfo {
         if self.parentInfo.startToken.txt == "" {
            offset = 0;
         } else {
            offset = indentDelta;
         }
         if self.parentInfo.frontToken$.pos$.lineNo ~= startToken.pos.lineNo and
            not self.parentInfo.isWaitingFront and
            not (startToken.txt == "{" or startToken.txt == "`{")
         {
            offset = offset + indentDelta;
         }
         termIndent = ParenInfoIndent.RelTerm( self.parentInfo, offset );
      }
      let mut indent = ParenInfoIndent.Abs( 1 );
      if parentInfo {
         indent = ParenInfoIndent.RelTerm( self.parentInfo, offset + indentDelta );
      }
      if startToken.txt == "case" {
         indent = ParenInfoIndent.RelTerm( self.parentInfo, indentDelta + 5 );
      } else {
         when! parentInfo {
            if parentInfo.startToken.txt == "case" {
               termIndent = parentInfo.parentInfo.indent;
               indent = ParenInfoIndent.RelTerm(
                  self.parentInfo.parentInfo, indentDelta * 2 );
            }
         }
      }
      self.termIndent = termIndent;
      self.indent = indent;
   }
}


pub class ParseCodeHook extend (Code.ParseCodeHookIF,Code.CodeTokenizerIF) {
   let tokenizer:Code.CodeTokenizerIF;
   /** 処理対象の行番号 */
   let mut targetLineNo:int;
   /** 最後に処理する行番号 */
   let endLineNo:int;
   /** 複数行を処理対象にする場合 */
   let multiLine:bool;
   // 行番号 → インデント
   let line2Indent:Line2Indent;
   let parenInfoStack:List<ParenInfo>;
   

   pub fn __init( tokenizer:Code.CodeTokenizerIF, startLineNo:int, endLineNo:int ) {

      let mut line2Indent = new Line2Indent();
      self.line2Indent = line2Indent;
      
      self.parenInfoStack = [];
      self.parenInfoStack.insert(
         new ParenInfo( line2Indent, nil, 1, LnsTypes.noneToken ) );
         
      self.tokenizer = tokenizer;
      self.targetLineNo = startLineNo;
      self.endLineNo = endLineNo;
      self.multiLine = startLineNo ~= endLineNo;
   }

   pub fn prepare( elementName:str, depth:int, token:&LnsTypes.Token ) mut {
   }

   fn dump() {
      foreach parenInfo, index in self.parenInfoStack {
         if index > 1 {
            Util.log( "-------",
                      getTokenTxt( parenInfo.$startToken ),
                      parenInfo.$termIndent, parenInfo.$stmtIndent );
         }
      }
   }

   fn output( token:&LnsTypes.Token, lineNo:int, indent:int ) mut {
      let pos = token.pos;

      {
         // コメントの処理
         let commentIndent;
         if termTxtSet.has( token.txt ) {
            // 終端トークンの直前のコメントのインデントは、前の token と同じにする
            let prev = self.line2Indent.getPrevIndent();
            if prev.$indent == indent {
               // 終端トークンと前の token のインデントが同じ場合は 一つ下げる。
               commentIndent = indent + indentDelta;
            } else {
               commentIndent = prev.$indent;
            }
         } else {
            commentIndent = indent;
         }
         foreach comment in token.$commentList {
            let work = new LineIndent(
               comment, commentIndent, lineNo, commentIndent - pos.column );
            self.line2Indent.add( comment.pos.lineNo, work );
         }
      }
         
      
      let lineIndent = new LineIndent( token, indent, lineNo, indent - pos.column );
      self.line2Indent.add( pos.lineNo, lineIndent );
      
      self.targetLineNo = pos.lineNo + 1;

      
      
      if pos.lineNo < self.endLineNo {
         return;
      }
         
     
      self.dump();
      self.line2Indent.outputResult( io.stdout );
   }

   
   fn checkKeyword( token:&LnsTypes.Token ) mut : &LnsTypes.Token {
      {
         switch token.kind {
            case .Str, .Cmnt {
               // 複数行のコメント、文字列内をインデント対象にしないように判定
               let list = LnsUtil.splitStr( token.txt, "\n");
               if #list > 0 and
                  token.pos.lineNo <= self.targetLineNo and
                  token.pos.lineNo + #list >= self.targetLineNo
               {
                  Util.log( __func__, "skip -- %s" (token.kind.$_txt) );
                  
                  self.targetLineNo = token.pos.lineNo + #list + 1;
                  return token;
               }
            }
         }
      }

      
      fn process() __trans : int, int {
         let parenInfo = self.parenInfoStack[ #self.parenInfoStack ];
         return __line__, parenInfo.$indent;
      }
      
      if token.txt == "___LNS___" or
         ( token.pos.lineNo > self.targetLineNo or
               token.pos.lineNo == self.targetLineNo ) and
         not termTxtSet.has( token.txt ) and
         not beginTxtSet.has( token.txt )
      //         token.txt ~= "{"
      {
         self.output( token, process()** );
      }
      return token;
   }

   
   pub fn getToken() mut : &LnsTypes.Token {
      return self.checkKeyword( self.tokenizer.getToken() );
   }
   pub fn peekToken() mut : &LnsTypes.Token {
      return self.checkKeyword( self.tokenizer.peekToken() );
   }

   pub fn process( parseCodeRet:Code.ParseCodeRet, depth:int ) mut : Code.ParseCodeRet {
      match parseCodeRet {
         case .Detect(codeCore) {
            let mut nowParenInfo = self.parenInfoStack[ #self.parenInfoStack ];
            let mut parenInfo = nowParenInfo;

            fn processTokens( token:&LnsTypes.Token ) __trans {
               let mut isWaitingFront = false;
               if parenMap[ token.txt ] {
                  parenInfo = new ParenInfo(
                     self.line2Indent,
                     self.parenInfoStack[ #self.parenInfoStack ], depth, token );
                  self.parenInfoStack.insert( parenInfo );
                  Util.log( __func__, "push", getTokenTxt( parenInfo.$startToken ) );
               } elseif parenInfo.$termTxt == token.txt {
                  Util.log( __func__, "pop", getTokenTxt( parenInfo.$startToken ) );

                  if parenInfo.$depth >= depth {
                     self.parenInfoStack.remove(##);
                     parenInfo = self.parenInfoStack[ #self.parenInfoStack ];
                  }
                  if parenInfo.$startToken.txt == "case" {
                     self.parenInfoStack.remove(##);
                     parenInfo = self.parenInfoStack[ #self.parenInfoStack ];
                  }
                  if token.txt == "}" {
                     isWaitingFront = true;
                  }
               } else {
                  if indentTermTxtSet.has( token.txt ) {
                     isWaitingFront = true;
                  } else {
                     parenInfo.set_contToken( token );
                  }
               }

               if ( token.pos.lineNo > self.targetLineNo or
                       token.pos.lineNo == self.targetLineNo )
               {
                  if termTxtSet.has( token.txt ) {
                     let indent = nowParenInfo.$termIndent;
                     self.output( token, __line__, indent );
                  } elseif beginTxtSet.has( token.txt ) {
                     let indent = parenInfo.$termIndent;
                     self.output( token, __line__, indent );
                  }
               }
               if isWaitingFront {
                  parenInfo.set_frontToken( nil );
               }
            }
            

            if! let codeCoreToken = codeCore@@@Code.CodeCoreToken {
               let token = codeCoreToken.$token;

               processTokens( token );
            } else {
               if! let workCoreToken = codeCore@@@Code.CodeCoreBuiltin {
                  processTokens( workCoreToken.$token );
               } else {
                  if! let workCoreToken = codeCore@@@Code.CodeCoreStat {
                     foreach token in workCoreToken.$list {
                        processTokens( token );
                     }
                  } else {
                     if! let workCoreToken = codeCore@@@Code.CodeCoreStatOne {
                        processTokens( workCoreToken.$token );
                     }
                  }
               }
            }
         }
         default {
            let mut parenInfo = self.parenInfoStack[ #self.parenInfoStack ];
            while parenInfo.$depth > depth {
               Util.log( __func__, "pushback", getTokenTxt( parenInfo.$startToken ) );
               self.parenInfoStack.remove( ## );
               parenInfo = self.parenInfoStack[ #self.parenInfoStack ];
            }
         }
      }

      if depth == 0 {
         self.line2Indent.outputResult( io.stdout );
      }

      
      return parseCodeRet;
   }

   
   
   advertise tokenizer;
}




pub class SimpleParser {
   let tokenizer:Code.CodeTokenizerIF;
   /** 処理対象の行番号 */
   let mut targetLineNo:int;
   /** 最後に処理する行番号 */
   let endLineNo:int;
   // 行番号 → インデント
   let line2Indent:Line2Indent;
   let parenInfoStack:List<ParenInfo>;
   

   pub fn __init( tokenizer:Code.CodeTokenizerIF, startLineNo:int, endLineNo:int ) {

      let mut line2Indent = new Line2Indent();
      self.line2Indent = line2Indent;
      
      self.parenInfoStack = [];
      self.parenInfoStack.insert(
         new ParenInfo( line2Indent, nil, 1, LnsTypes.noneToken ) );
         
      self.tokenizer = tokenizer;
      self.targetLineNo = startLineNo;
      self.endLineNo = endLineNo;
   }


   fn dump() {
      foreach parenInfo, index in self.parenInfoStack {
         if index > 1 {
            Util.log( "-------",
                      getTokenTxt( parenInfo.$startToken ),
                      parenInfo.$termIndent, parenInfo.$stmtIndent );
         }
      }
   }

   fn output( token:&LnsTypes.Token, parenInfo:&ParenInfo,
              lineNo:int, indent:int ) mut : bool
   {
      let pos = token.pos;

      {
         // コメントの処理
         let commentIndent = parenInfo.$stmtIndent;
         foreach comment in  token.$commentList {
            let work = new LineIndent(
               comment, commentIndent, lineNo, commentIndent - pos.column );
            // 複数行コメントは、コメント内の行を全て同じインデントにする。
            let list = LnsUtil.splitStr( comment.txt, "\n" );
            if #list > 0 {
               foreach _, index in list {
                  self.line2Indent.add( comment.pos.lineNo + index - 1, work );
               }
            } else {
               self.line2Indent.add( comment.pos.lineNo, work );
            }
         }
      }
         
      
      let lineIndent = new LineIndent( token, indent, lineNo, indent - pos.column );
      self.line2Indent.add( pos.lineNo, lineIndent );
      
      self.targetLineNo = pos.lineNo + 1;

      
      
      return pos.lineNo < self.endLineNo;
   }

   
   fn checkKeyword( token:&LnsTypes.Token ) mut : &LnsTypes.Token! {
      {
         switch token.kind {
            case .Str, .Cmnt {
               // 複数行のコメント、文字列内をインデント対象にしないように判定
               let list = LnsUtil.splitStr( token.txt, "\n");
               if #list > 0 and
                  token.pos.lineNo <= self.targetLineNo and
                  token.pos.lineNo + #list >= self.targetLineNo
               {
                  Util.log( __func__, "skip -- %s" (token.kind.$_txt) );
                  
                  self.targetLineNo = token.pos.lineNo + #list + 1;
                  return token;
               }
            }
         }
      }

      
      fn process() __trans : int, int {
         let parenInfo = self.parenInfoStack[ #self.parenInfoStack ];
         return __line__, parenInfo.$indent;
      }
      
      if token.txt == "___LNS___" or
         ( token.pos.lineNo > self.targetLineNo or
              token.pos.lineNo == self.targetLineNo ) and
         not termTxtSet.has( token.txt ) and
         not beginTxtSet.has( token.txt )
      {
         if not self.output( token, self.parenInfoStack[ #self.parenInfoStack ],
                             process()** ) {
            return nil;
         }
      }
      return token;
   }


   fn getToken() mut : &LnsTypes.Token! {
      return self.checkKeyword( self.tokenizer.getToken() );
   }

   fn process( token:&LnsTypes.Token ) mut : bool {
      let mut nowParenInfo = self.parenInfoStack[ #self.parenInfoStack ];
      let mut parenInfo = nowParenInfo;

      let depth = 1;

      let mut isWaitingFront = false;
      if parenMap[ token.txt ] {
         parenInfo = new ParenInfo(
            self.line2Indent,
            self.parenInfoStack[ #self.parenInfoStack ], depth, token );
         self.parenInfoStack.insert( parenInfo );
         Util.log( __func__, "push", getTokenTxt( parenInfo.$startToken ) );
      } elseif parenInfo.$termTxt == token.txt {
         Util.log( __func__, "pop", getTokenTxt( parenInfo.$startToken ) );

         if parenInfo.$depth >= depth {
            self.parenInfoStack.remove(##);
            parenInfo = self.parenInfoStack[ #self.parenInfoStack ];
         }
         if parenInfo.$startToken.txt == "case" {
            self.parenInfoStack.remove(##);
            parenInfo = self.parenInfoStack[ #self.parenInfoStack ];
         }
         if token.txt == "}" {
            isWaitingFront = true;
         }
      } else {
         if indentTermTxtSet.has( token.txt ) {
            isWaitingFront = true;
         } else {
            parenInfo.set_contToken( token );
         }
      }

      let continue;
      if ( token.pos.lineNo > self.targetLineNo or
              token.pos.lineNo == self.targetLineNo )
      {
         if termTxtSet.has( token.txt ) {
            let indent = nowParenInfo.$termIndent;
            continue = self.output( token, nowParenInfo, __line__, indent );
         } elseif beginTxtSet.has( token.txt ) {
            let indent = parenInfo.$termIndent;
            continue = self.output( token, nowParenInfo, __line__, indent );
         } else {
            continue = true;
         }
      } else {
         continue = true;
      }
      if isWaitingFront {
         parenInfo.set_frontToken( nil );
      }

      return continue;
   }

   pub fn analyze() mut : &Line2Indent {
      while true {
         let! token = self.getToken() {
            break;
         };
         
         // {
         //    if prev.pos.lineNo ~= token.pos.lineNo {
         //       print( "" );
         //    }
         //    io.stdout.write( token.txt .. " " );
         //    prev = token;
         // }

         if token.kind == .Eof {
            break;
         }

         if not self.process( token ) {
            break;
         }
      }
      return self.line2Indent;
   }
}
